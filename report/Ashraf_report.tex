%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%                                                             %%%
%%%      File: report.tex                                       %%%
%%%    Author: Sabine Schulte im Walde                          %%%
%%%   Purpose: Data report template                             %%%
%%%                                                             %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[11pt,a4paper]{article}

\usepackage{a4wide}
\usepackage{times}
\usepackage[utf8]{inputenc}

\usepackage[square,sort,comma,numbers]{natbib}


\begin{document}

\title{Large Scale Data Exploration with R}
\author{Ashraf, Shawon}
\date{26 June, 2020}

\maketitle


\section{Norms}

\subsection{Dataset}

\paragraph{}
For this data exploration project, I have used the Norms dataset presented by Brysbaert et al. \cite{brys} which contains the concreteness ratings for 40 thousand generally known English word lemmas. According to the authors, concreteness is the measurement of the concept a word demotes to an entity. The concept of concreteness of words came Paivioâ€™s dual-coding theory \cite{paivio} which states that concrete words are easier to recall and activate in memory compared to non concrete words. Also,  Schwanenflugel et al. \citep{schwanenflugel} presented that concrete words are easier to recall because of the supporting memory context imposed by the words on entities to the degree abstract words can not. Vigliocco et al. \cite{vigliocco_vinson_lewis_garrett_2004} and Andrews et al. \cite{andrews_vigliocco_vinson_2009} presented a semantic theory which states that the learning process of words are more based on direct experience of the learners.

\paragraph{}
The authors based their presentation of the Norms based on Connell et al. \cite{connell} which states that despite words being learnt on direct experiences, the existing concreteness ratings were too much focused on visual perception whereas Lynott et al. found that the concreteness ratings were correlated not only on visual perception but also on touch and smell. The overcome the limitations of the existing datasets, the authors came up with the dataset in use which was collected by asking English speakers to rate the concreteness of the words based on their knowledge on them.

\paragraph{}
The Norms dataset consist of 8 columns :
\begin{enumerate}
	\item Word
	\item Whether the word is a Bigram or not
	\item Mean concreteness rating
	\item Standard deviation of the concreteness ratings
	\item Number of persons not knowing the word
	\item Total number or persons rating words
	\item Percentage of persons knowing the word
	\item SUBTLEX-US frequency count of the word \cite{brysbaert_new_2009}
\end{enumerate}

\subsection{Variables chosen}

\begin{itemize}
	\item Mean concreteness rating
	\item Standard deviation of the concreteness ratings
	\item Percentage of persons knowing the word
\end{itemize}


\section{Preprocessing}
\paragraph{}
The provided datasets were processed using unix tools such as awk, cat, etc.

\subsection{Windows}
\begin{itemize}
	\item POS : NN
	\item Frequency count : Greater than 20000
	\item Excluded characters : ":::"
	\item The processed output was converted to a csv file for importing into R
	\item Reduced from 49776264 items to 11046 after processing
\end{itemize}

\subsection{Frequencies}
\begin{itemize}
	\item POS : NN
	\item Frequency count : Greater than 5000
	\item The processed output was converted to a csv file for importing into R
	\item Reduced from 326775 items to 59947 after processing
\end{itemize}


\subsection{Norms}
\paragraph{}
The Norms dataset was already provided in .xlsx format and did not need preprocessing via Unix tools. Norms with words having the POS tag Noun were extracted using R function `subset` during analysis.


\section{Descriptive Statistics and plots of Norms}

\subsection{Descriptive Statistics}
\paragraph{}
GG


% Bibliography:

\bibliography{refs}
\bibliographystyle{ieeetr}


\end{document}


%% --- END OF FILE